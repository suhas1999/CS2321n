{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs231n_assignment1_softmax.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "QXhD6tRYais7",
        "colab_type": "code",
        "outputId": "ab7e9668-6cc7-408c-9554-278aade6f89c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7U_Dm7v4axWU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# for auto-reloading extenrnal modules\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "awQ9y1DV_D_l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "465f403e-0f6b-4786-e2ca-80f063c73ef2"
      },
      "cell_type": "code",
      "source": [
        "!pip install pydrive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydrive\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e0/0e64788e5dd58ce2d6934549676243dc69d982f198524be9b99e9c2a4fd5/PyDrive-1.3.1.tar.gz (987kB)\n",
            "\u001b[K    100% |████████████████████████████████| 993kB 21.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.6.7)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.11.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.11.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Building wheels for collected packages: pydrive\n",
            "  Running setup.py bdist_wheel for pydrive ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/fa/d2/9a/d3b6b506c2da98289e5d417215ce34b696db856643bad779f4\n",
            "Successfully built pydrive\n",
            "Installing collected packages: pydrive\n",
            "Successfully installed pydrive-1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C64Wpe1d_ECW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "a17f4dde-21cc-4237-d575-cb14ad2ab929"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LxGJiiJW_EGV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "3651deb3-a498-49e7-dacb-3e8a247d75d8"
      },
      "cell_type": "code",
      "source": [
        "!wget http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
        "!tar -xzvf cifar-10-python.tar.gz\n",
        "!rm cifar-10-python.tar.gz "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-26 10:10:04--  http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-python.tar.gz’\n",
            "\n",
            "cifar-10-python.tar 100%[===================>] 162.60M  16.5MB/s    in 11s     \n",
            "\n",
            "2018-12-26 10:10:15 (15.2 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
            "\n",
            "cifar-10-batches-py/\n",
            "cifar-10-batches-py/data_batch_4\n",
            "cifar-10-batches-py/readme.html\n",
            "cifar-10-batches-py/test_batch\n",
            "cifar-10-batches-py/data_batch_3\n",
            "cifar-10-batches-py/batches.meta\n",
            "cifar-10-batches-py/data_batch_2\n",
            "cifar-10-batches-py/data_batch_5\n",
            "cifar-10-batches-py/data_batch_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9_tbbnzpbEHM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from six.moves import cPickle as pickle\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.misc import imread\n",
        "import platform\n",
        "\n",
        "def load_pickle(f):\n",
        "    version = platform.python_version_tuple()\n",
        "    if version[0] == '2':\n",
        "        return  pickle.load(f)\n",
        "    elif version[0] == '3':\n",
        "        return  pickle.load(f, encoding='latin1')\n",
        "    raise ValueError(\"invalid python version: {}\".format(version))\n",
        "\n",
        "def load_CIFAR_batch(filename):\n",
        "  \"\"\" load single batch of cifar \"\"\"\n",
        "  with open(filename, 'rb') as f:\n",
        "    datadict = load_pickle(f)\n",
        "    X = datadict['data']\n",
        "    Y = datadict['labels']\n",
        "    X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
        "    Y = np.array(Y)\n",
        "    return X, Y\n",
        "\n",
        "def load_CIFAR10(ROOT):\n",
        "  \"\"\" load all of cifar \"\"\"\n",
        "  xs = []\n",
        "  ys = []\n",
        "  for b in range(1,6):\n",
        "    f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
        "    X, Y = load_CIFAR_batch(f)\n",
        "    xs.append(X)\n",
        "    ys.append(Y)    \n",
        "  Xtr = np.concatenate(xs)\n",
        "  Ytr = np.concatenate(ys)\n",
        "  del X, Y\n",
        "  Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
        "  return Xtr, Ytr, Xte, Yte\n",
        "\n",
        "\n",
        "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000,\n",
        "                     subtract_mean=True):\n",
        "    \"\"\"\n",
        "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
        "    it for classifiers. These are the same steps as we used for the SVM, but\n",
        "    condensed to a single function.\n",
        "    \"\"\"\n",
        "    # Load the raw CIFAR-10 data\n",
        "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
        "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
        "        \n",
        "    # Subsample the data\n",
        "    mask = list(range(num_training, num_training + num_validation))\n",
        "    X_val = X_train[mask]\n",
        "    y_val = y_train[mask]\n",
        "    mask = list(range(num_training))\n",
        "    X_train = X_train[mask]\n",
        "    y_train = y_train[mask]\n",
        "    mask = list(range(num_test))\n",
        "    X_test = X_test[mask]\n",
        "    y_test = y_test[mask]\n",
        "\n",
        "    # Normalize the data: subtract the mean image\n",
        "    if subtract_mean:\n",
        "      mean_image = np.mean(X_train, axis=0)\n",
        "      X_train -= mean_image\n",
        "      X_val -= mean_image\n",
        "      X_test -= mean_image\n",
        "    \n",
        "    # Transpose so that channels come first\n",
        "    X_train = X_train.transpose(0, 3, 1, 2).copy()\n",
        "    X_val = X_val.transpose(0, 3, 1, 2).copy()\n",
        "    X_test = X_test.transpose(0, 3, 1, 2).copy()\n",
        "\n",
        "    # Package data into a dictionary\n",
        "    return {\n",
        "      'X_train': X_train, 'y_train': y_train,\n",
        "      'X_val': X_val, 'y_val': y_val,\n",
        "      'X_test': X_test, 'y_test': y_test,\n",
        "    }\n",
        "    \n",
        "\n",
        "def load_tiny_imagenet(path, dtype=np.float32, subtract_mean=True):\n",
        "  \"\"\"\n",
        "  Load TinyImageNet. Each of TinyImageNet-100-A, TinyImageNet-100-B, and\n",
        "  TinyImageNet-200 have the same directory structure, so this can be used\n",
        "  to load any of them.\n",
        "\n",
        "  Inputs:\n",
        "  - path: String giving path to the directory to load.\n",
        "  - dtype: numpy datatype used to load the data.\n",
        "  - subtract_mean: Whether to subtract the mean training image.\n",
        "\n",
        "  Returns: A dictionary with the following entries:\n",
        "  - class_names: A list where class_names[i] is a list of strings giving the\n",
        "    WordNet names for class i in the loaded dataset.\n",
        "  - X_train: (N_tr, 3, 64, 64) array of training images\n",
        "  - y_train: (N_tr,) array of training labels\n",
        "  - X_val: (N_val, 3, 64, 64) array of validation images\n",
        "  - y_val: (N_val,) array of validation labels\n",
        "  - X_test: (N_test, 3, 64, 64) array of testing images.\n",
        "  - y_test: (N_test,) array of test labels; if test labels are not available\n",
        "    (such as in student code) then y_test will be None.\n",
        "  - mean_image: (3, 64, 64) array giving mean training image\n",
        "  \"\"\"\n",
        "  # First load wnids\n",
        "  with open(os.path.join(path, 'wnids.txt'), 'r') as f:\n",
        "    wnids = [x.strip() for x in f]\n",
        "\n",
        "  # Map wnids to integer labels\n",
        "  wnid_to_label = {wnid: i for i, wnid in enumerate(wnids)}\n",
        "\n",
        "  # Use words.txt to get names for each class\n",
        "  with open(os.path.join(path, 'words.txt'), 'r') as f:\n",
        "    wnid_to_words = dict(line.split('\\t') for line in f)\n",
        "    for wnid, words in wnid_to_words.iteritems():\n",
        "      wnid_to_words[wnid] = [w.strip() for w in words.split(',')]\n",
        "  class_names = [wnid_to_words[wnid] for wnid in wnids]\n",
        "\n",
        "  # Next load training data.\n",
        "  X_train = []\n",
        "  y_train = []\n",
        "  for i, wnid in enumerate(wnids):\n",
        "    if (i + 1) % 20 == 0:\n",
        "      print('loading training data for synset %d / %d' % (i + 1, len(wnids)))\n",
        "    # To figure out the filenames we need to open the boxes file\n",
        "    boxes_file = os.path.join(path, 'train', wnid, '%s_boxes.txt' % wnid)\n",
        "    with open(boxes_file, 'r') as f:\n",
        "      filenames = [x.split('\\t')[0] for x in f]\n",
        "    num_images = len(filenames)\n",
        "    \n",
        "    X_train_block = np.zeros((num_images, 3, 64, 64), dtype=dtype)\n",
        "    y_train_block = wnid_to_label[wnid] * np.ones(num_images, dtype=np.int64)\n",
        "    for j, img_file in enumerate(filenames):\n",
        "      img_file = os.path.join(path, 'train', wnid, 'images', img_file)\n",
        "      img = imread(img_file)\n",
        "      if img.ndim == 2:\n",
        "        ## grayscale file\n",
        "        img.shape = (64, 64, 1)\n",
        "      X_train_block[j] = img.transpose(2, 0, 1)\n",
        "    X_train.append(X_train_block)\n",
        "    y_train.append(y_train_block)\n",
        "      \n",
        "  # We need to concatenate all training data\n",
        "  X_train = np.concatenate(X_train, axis=0)\n",
        "  y_train = np.concatenate(y_train, axis=0)\n",
        "  \n",
        "  # Next load validation data\n",
        "  with open(os.path.join(path, 'val', 'val_annotations.txt'), 'r') as f:\n",
        "    img_files = []\n",
        "    val_wnids = []\n",
        "    for line in f:\n",
        "      img_file, wnid = line.split('\\t')[:2]\n",
        "      img_files.append(img_file)\n",
        "      val_wnids.append(wnid)\n",
        "    num_val = len(img_files)\n",
        "    y_val = np.array([wnid_to_label[wnid] for wnid in val_wnids])\n",
        "    X_val = np.zeros((num_val, 3, 64, 64), dtype=dtype)\n",
        "    for i, img_file in enumerate(img_files):\n",
        "      img_file = os.path.join(path, 'val', 'images', img_file)\n",
        "      img = imread(img_file)\n",
        "      if img.ndim == 2:\n",
        "        img.shape = (64, 64, 1)\n",
        "      X_val[i] = img.transpose(2, 0, 1)\n",
        "\n",
        "  # Next load test images\n",
        "  # Students won't have test labels, so we need to iterate over files in the\n",
        "  # images directory.\n",
        "  img_files = os.listdir(os.path.join(path, 'test', 'images'))\n",
        "  X_test = np.zeros((len(img_files), 3, 64, 64), dtype=dtype)\n",
        "  for i, img_file in enumerate(img_files):\n",
        "    img_file = os.path.join(path, 'test', 'images', img_file)\n",
        "    img = imread(img_file)\n",
        "    if img.ndim == 2:\n",
        "      img.shape = (64, 64, 1)\n",
        "    X_test[i] = img.transpose(2, 0, 1)\n",
        "\n",
        "  y_test = None\n",
        "  y_test_file = os.path.join(path, 'test', 'test_annotations.txt')\n",
        "  if os.path.isfile(y_test_file):\n",
        "    with open(y_test_file, 'r') as f:\n",
        "      img_file_to_wnid = {}\n",
        "      for line in f:\n",
        "        line = line.split('\\t')\n",
        "        img_file_to_wnid[line[0]] = line[1]\n",
        "    y_test = [wnid_to_label[img_file_to_wnid[img_file]] for img_file in img_files]\n",
        "    y_test = np.array(y_test)\n",
        "  \n",
        "  mean_image = X_train.mean(axis=0)\n",
        "  if subtract_mean:\n",
        "    X_train -= mean_image[None]\n",
        "    X_val -= mean_image[None]\n",
        "    X_test -= mean_image[None]\n",
        "\n",
        "  return {\n",
        "    'class_names': class_names,\n",
        "    'X_train': X_train,\n",
        "    'y_train': y_train,\n",
        "    'X_val': X_val,\n",
        "    'y_val': y_val,\n",
        "    'X_test': X_test,\n",
        "    'y_test': y_test,\n",
        "    'class_names': class_names,\n",
        "    'mean_image': mean_image,\n",
        "  }\n",
        "\n",
        "\n",
        "def load_models(models_dir):\n",
        "  \"\"\"\n",
        "  Load saved models from disk. This will attempt to unpickle all files in a\n",
        "  directory; any files that give errors on unpickling (such as README.txt) will\n",
        "  be skipped.\n",
        "\n",
        "  Inputs:\n",
        "  - models_dir: String giving the path to a directory containing model files.\n",
        "    Each model file is a pickled dictionary with a 'model' field.\n",
        "\n",
        "  Returns:\n",
        "  A dictionary mapping model file names to models.\n",
        "  \"\"\"\n",
        "  models = {}\n",
        "  for model_file in os.listdir(models_dir):\n",
        "    with open(os.path.join(models_dir, model_file), 'rb') as f:\n",
        "      try:\n",
        "        models[model_file] = load_pickle(f)['model']\n",
        "      except pickle.UnpicklingError:\n",
        "        continue\n",
        "  return models\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hbayuf0MbPNU",
        "colab_type": "code",
        "outputId": "aac6a79e-cb08-47ea-de10-049127f6bd53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "cell_type": "code",
      "source": [
        "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
        "    \"\"\"\n",
        "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
        "    it for the linear classifier. These are the same steps as we used for the\n",
        "    SVM, but condensed to a single function.  \n",
        "    \"\"\"\n",
        "    # Load the raw CIFAR-10 data\n",
        "    cifar10_dir = './cifar-10-batches-py'\n",
        "    \n",
        "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
        "    \n",
        "    # subsample the data\n",
        "    mask = list(range(num_training, num_training + num_validation))\n",
        "    X_val = X_train[mask]\n",
        "    y_val = y_train[mask]\n",
        "    mask = list(range(num_training))\n",
        "    X_train = X_train[mask]\n",
        "    y_train = y_train[mask]\n",
        "    mask = list(range(num_test))\n",
        "    X_test = X_test[mask]\n",
        "    y_test = y_test[mask]\n",
        "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
        "    X_dev = X_train[mask]\n",
        "    y_dev = y_train[mask]\n",
        "    \n",
        "    # Preprocessing: reshape the image data into rows\n",
        "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
        "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
        "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
        "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
        "    \n",
        "    # Normalize the data: subtract the mean image\n",
        "    mean_image = np.mean(X_train, axis = 0)\n",
        "    X_train -= mean_image\n",
        "    X_val -= mean_image\n",
        "    X_test -= mean_image\n",
        "    X_dev -= mean_image\n",
        "    \n",
        "    # add bias dimension and transform into columns\n",
        "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
        "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
        "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
        "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
        "    \n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
        "\n",
        "\n",
        "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
        "try:\n",
        "   del X_train, y_train\n",
        "   del X_test, y_test\n",
        "   print('Clear previously loaded data.')\n",
        "except:\n",
        "   pass\n",
        "\n",
        "# Invoke the above function to get our data.\n",
        "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
        "print('Train data shape: ', X_train.shape)\n",
        "print('Train labels shape: ', y_train.shape)\n",
        "print('Validation data shape: ', X_val.shape)\n",
        "print('Validation labels shape: ', y_val.shape)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test labels shape: ', y_test.shape)\n",
        "print('dev data shape: ', X_dev.shape)\n",
        "print('dev labels shape: ', y_dev.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data shape:  (49000, 3073)\n",
            "Train labels shape:  (49000,)\n",
            "Validation data shape:  (1000, 3073)\n",
            "Validation labels shape:  (1000,)\n",
            "Test data shape:  (1000, 3073)\n",
            "Test labels shape:  (1000,)\n",
            "dev data shape:  (500, 3073)\n",
            "dev labels shape:  (500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oKCGKdhwbrbj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from random import shuffle\n",
        "\n",
        "def softmax_loss_naive(W, X, y, reg):\n",
        "  \"\"\"\n",
        "  Softmax loss function, naive implementation (with loops)\n",
        "\n",
        "  Inputs have dimension D, there are C classes, and we operate on minibatches\n",
        "  of N examples.\n",
        "  \n",
        "  Inputs:\n",
        "  - W: A numpy array of shape (D, C) containing weights.\n",
        "  - X: A numpy array of shape (N, D) containing a minibatch of data.\n",
        "  - y: A numpy array of shape (N,) containing training labels; y[i] = c means\n",
        "    that X[i] has label c, where 0 <= c < C.\n",
        "  - reg: (float) regularization strength\n",
        "\n",
        "  Returns a tuple of:\n",
        "  - loss as single float\n",
        "  - gradient with respect to weights W; an array of same shape as W\n",
        "  \"\"\"\n",
        "  # Initialize the loss and gradient to zero.\n",
        "  loss = 0.0\n",
        "  dW = np.zeros_like(W)\n",
        "  num_train = X.shape[0]\n",
        "  num_classes = W.shape[1]\n",
        "  import math\n",
        "  #############################################################################\n",
        "  # TODO: Compute the softmax loss and its gradient using explicit loops.     #\n",
        "  # Store the loss in loss and the gradient in dW. If you are not careful     #\n",
        "  # here, it is easy to run into numeric instability. Don't forget the        #\n",
        "  # regularization!                                                           #\n",
        "  #############################################################################\n",
        "  for i in range(num_train):\n",
        "    # Compute vector of scores\n",
        "    f_i = X[i].dot(W)\n",
        "\n",
        "    # Normalization trick to avoid numerical instability, per http://cs231n.github.io/linear-classify/#softmax\n",
        "    f_i -= np.max(f_i)\n",
        "\n",
        "    # Compute loss (and add to it, divided later)\n",
        "    sum_j = np.sum(np.exp(f_i))\n",
        "    p = lambda k: np.exp(f_i[k]) / sum_j\n",
        "    loss += -np.log(p(y[i]))\n",
        "\n",
        "    # Compute gradient\n",
        "    # Here we are computing the contribution to the inner sum for a given i.\n",
        "    for k in range(num_classes):\n",
        "      p_k = p(k)\n",
        "      dW[:, k] += (p_k - (k == y[i])) * X[i]\n",
        "\n",
        "  loss /= num_train\n",
        "  loss += 0.5 * reg * np.sum(W * W)\n",
        "  dW /= num_train\n",
        "  dW += reg*W\n",
        "  #############################################################################\n",
        "  #                          END OF YOUR CODE                                 #\n",
        "  #############################################################################\n",
        "\n",
        "  return loss, dW\n",
        "\n",
        "\n",
        "def softmax_loss_vectorized(W, X, y, reg):\n",
        "  \"\"\"\n",
        "  Softmax loss function, vectorized version.\n",
        "\n",
        "  Inputs and outputs are the same as softmax_loss_naive.\n",
        "  \"\"\"\n",
        "  # Initialize the loss and gradient to zero.\n",
        "  loss = 0.0\n",
        "  dW = np.zeros_like(W)\n",
        "  num_train = X.shape[0]\n",
        "  #############################################################################\n",
        "  # TODO: Compute the softmax loss and its gradient using no explicit loops.  #\n",
        "  # Store the loss in loss and the gradient in dW. If you are not careful     #\n",
        "  # here, it is easy to run into numeric instability. Don't forget the        #\n",
        "  # regularization!                                                           #\n",
        "  #############################################################################\n",
        "  #scores = np.dot(X,W)\n",
        "  #total_deno = np.sum(np.exp(scores),axis =1, keepdims=True)\n",
        "  #p = np.exp(scores)/total_deno\n",
        "  ##loss = np.sum(-np.log(p[np.arange(num_train),y]))\n",
        "  f = X.dot(W)\n",
        "  f -= np.max(f, axis=1, keepdims=True) # max of every sample\n",
        "  sum_f = np.sum(np.exp(f), axis=1, keepdims=True)\n",
        "  p = np.exp(f)/sum_f\n",
        "\n",
        "  loss = np.sum(-np.log(p[np.arange(num_train), y]))\n",
        "\n",
        "  ind = np.zeros_like(p)\n",
        "  ind[np.arange(num_train), y] = 1\n",
        "  dW = X.T.dot(p - ind)\n",
        "\n",
        "  loss /= num_train\n",
        "  loss += 0.5 * reg * np.sum(W * W)\n",
        "  dW /= num_train\n",
        "  dW += reg*W\n",
        "  \n",
        "  #zeroes = np.zeros_like(p)\n",
        "  #zeroes[np.arange(num_train),y]=1\n",
        "  #dW =  X.T.dot(p-zeroes)\n",
        "  #loss = loss/num_train\n",
        "  #dW = dW/num_train \n",
        "  #loss = loss + 0.5 * reg * np.sum(W*W)\n",
        "  #dW = dW+ reg*(W)\n",
        "  #############################################################################\n",
        "  #                          END OF YOUR CODE                                 #\n",
        "  #############################################################################\n",
        "\n",
        "  return loss, dW\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uJaynSA0cZdN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2cc816cf-fc4a-4960-d4ce-c767a933bcc7"
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Generate a random softmax weight matrix and use it to compute the loss.\n",
        "W = np.random.randn(3073, 10) * 0.0001\n",
        "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
        "\n",
        "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
        "print('loss: %f' % loss)\n",
        "print('sanity check: %f' % (-np.log(0.1)))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 2.345877\n",
            "sanity check: 2.302585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7mOaMCsuFkkg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "from random import randrange\n",
        "\n",
        "def eval_numerical_gradient(f, x, verbose=True, h=0.00001):\n",
        "  \"\"\" \n",
        "  a naive implementation of numerical gradient of f at x \n",
        "  - f should be a function that takes a single argument\n",
        "  - x is the point (numpy array) to evaluate the gradient at\n",
        "  \"\"\" \n",
        "\n",
        "  fx = f(x) # evaluate function value at original point\n",
        "  grad = np.zeros_like(x)\n",
        "  # iterate over all indexes in x\n",
        "  it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "  while not it.finished:\n",
        "\n",
        "    # evaluate function at x+h\n",
        "    ix = it.multi_index\n",
        "    oldval = x[ix]\n",
        "    x[ix] = oldval + h # increment by h\n",
        "    fxph = f(x) # evalute f(x + h)\n",
        "    x[ix] = oldval - h\n",
        "    fxmh = f(x) # evaluate f(x - h)\n",
        "    x[ix] = oldval # restore\n",
        "\n",
        "    # compute the partial derivative with centered formula\n",
        "    grad[ix] = (fxph - fxmh) / (2 * h) # the slope\n",
        "    if verbose:\n",
        "      print(ix, grad[ix])\n",
        "    it.iternext() # step to next dimension\n",
        "\n",
        "  return grad\n",
        "\n",
        "\n",
        "def eval_numerical_gradient_array(f, x, df, h=1e-5):\n",
        "  \"\"\"\n",
        "  Evaluate a numeric gradient for a function that accepts a numpy\n",
        "  array and returns a numpy array.\n",
        "  \"\"\"\n",
        "  grad = np.zeros_like(x)\n",
        "  it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "  while not it.finished:\n",
        "    ix = it.multi_index\n",
        "    \n",
        "    oldval = x[ix]\n",
        "    x[ix] = oldval + h\n",
        "    pos = f(x).copy()\n",
        "    x[ix] = oldval - h\n",
        "    neg = f(x).copy()\n",
        "    x[ix] = oldval\n",
        "    \n",
        "    grad[ix] = np.sum((pos - neg) * df) / (2 * h)\n",
        "    it.iternext()\n",
        "  return grad\n",
        "\n",
        "\n",
        "def eval_numerical_gradient_blobs(f, inputs, output, h=1e-5):\n",
        "  \"\"\"\n",
        "  Compute numeric gradients for a function that operates on input\n",
        "  and output blobs.\n",
        "  \n",
        "  We assume that f accepts several input blobs as arguments, followed by a blob\n",
        "  into which outputs will be written. For example, f might be called like this:\n",
        "\n",
        "  f(x, w, out)\n",
        "  \n",
        "  where x and w are input Blobs, and the result of f will be written to out.\n",
        "\n",
        "  Inputs: \n",
        "  - f: function\n",
        "  - inputs: tuple of input blobs\n",
        "  - output: output blob\n",
        "  - h: step size\n",
        "  \"\"\"\n",
        "  numeric_diffs = []\n",
        "  for input_blob in inputs:\n",
        "    diff = np.zeros_like(input_blob.diffs)\n",
        "    it = np.nditer(input_blob.vals, flags=['multi_index'],\n",
        "                   op_flags=['readwrite'])\n",
        "    while not it.finished:\n",
        "      idx = it.multi_index\n",
        "      orig = input_blob.vals[idx]\n",
        "\n",
        "      input_blob.vals[idx] = orig + h\n",
        "      f(*(inputs + (output,)))\n",
        "      pos = np.copy(output.vals)\n",
        "      input_blob.vals[idx] = orig - h\n",
        "      f(*(inputs + (output,)))\n",
        "      neg = np.copy(output.vals)\n",
        "      input_blob.vals[idx] = orig\n",
        "      \n",
        "      diff[idx] = np.sum((pos - neg) * output.diffs) / (2.0 * h)\n",
        "\n",
        "      it.iternext()\n",
        "    numeric_diffs.append(diff)\n",
        "  return numeric_diffs\n",
        "\n",
        "\n",
        "def eval_numerical_gradient_net(net, inputs, output, h=1e-5):\n",
        "  return eval_numerical_gradient_blobs(lambda *args: net.forward(),\n",
        "              inputs, output, h=h)\n",
        "\n",
        "\n",
        "def grad_check_sparse(f, x, analytic_grad, num_checks=10, h=1e-5):\n",
        "  \"\"\"\n",
        "  sample a few random elements and only return numerical\n",
        "  in this dimensions.\n",
        "  \"\"\"\n",
        "\n",
        "  for i in range(num_checks):\n",
        "    ix = tuple([randrange(m) for m in x.shape])\n",
        "\n",
        "    oldval = x[ix]\n",
        "    x[ix] = oldval + h # increment by h\n",
        "    fxph = f(x) # evaluate f(x + h)\n",
        "    x[ix] = oldval - h # increment by h\n",
        "    fxmh = f(x) # evaluate f(x - h)\n",
        "    x[ix] = oldval # reset\n",
        "\n",
        "    grad_numerical = (fxph - fxmh) / (2 * h)\n",
        "    grad_analytic = analytic_grad[ix]\n",
        "    rel_error = abs(grad_numerical - grad_analytic) / (abs(grad_numerical) + abs(grad_analytic))\n",
        "    print('numerical: %f analytic: %f, relative error: %e' % (grad_numerical, grad_analytic, rel_error))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pqCqk_BfHAYB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YbMLCmXvJYEb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "10c441df-0764-44b1-e755-36fdd64e024c"
      },
      "cell_type": "code",
      "source": [
        "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
        "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
        "\n",
        "# similar to SVM case, do another gradient check with regularization\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "numerical: -0.447442 analytic: -0.447442, relative error: 6.570273e-08\n",
            "numerical: -0.233545 analytic: -0.233545, relative error: 2.882311e-07\n",
            "numerical: 1.849760 analytic: 1.849760, relative error: 6.010621e-09\n",
            "numerical: -3.843526 analytic: -3.843526, relative error: 1.752273e-08\n",
            "numerical: -1.690424 analytic: -1.690424, relative error: 6.837094e-08\n",
            "numerical: -0.325343 analytic: -0.325343, relative error: 8.214149e-08\n",
            "numerical: -0.327409 analytic: -0.327409, relative error: 1.503084e-07\n",
            "numerical: 2.642302 analytic: 2.642302, relative error: 2.408271e-08\n",
            "numerical: 0.241705 analytic: 0.241705, relative error: 7.498490e-08\n",
            "numerical: -2.369546 analytic: -2.369546, relative error: 2.975901e-08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1Ev33kYLJeXh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "7eb19748-71be-4c73-b8c8-08548f5ab8a9"
      },
      "cell_type": "code",
      "source": [
        "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
        "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
        "grad_numerical = grad_check_sparse(f, W, grad, 10)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "numerical: 0.914686 analytic: 0.914686, relative error: 3.282071e-08\n",
            "numerical: -0.881722 analytic: -0.881722, relative error: 3.998820e-08\n",
            "numerical: 0.511625 analytic: 0.511625, relative error: 3.818372e-08\n",
            "numerical: 0.201319 analytic: 0.201318, relative error: 3.574415e-07\n",
            "numerical: 1.926780 analytic: 1.926780, relative error: 5.305684e-09\n",
            "numerical: 0.365279 analytic: 0.365279, relative error: 1.763649e-07\n",
            "numerical: 1.554349 analytic: 1.554349, relative error: 9.915507e-09\n",
            "numerical: -0.490425 analytic: -0.490425, relative error: 4.380214e-08\n",
            "numerical: 4.209245 analytic: 4.209245, relative error: 1.181559e-08\n",
            "numerical: 0.366149 analytic: 0.366149, relative error: 4.048941e-08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NtqyLkdKJiBX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c42f9fe6-dc07-4978-cfe0-f0d499e13b07"
      },
      "cell_type": "code",
      "source": [
        "tic = time.time()\n",
        "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
        "toc = time.time()\n",
        "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "naive loss: 2.345877e+00 computed in 0.250950s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UfpMOLy8JxCR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tic = time.time()\n",
        "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
        "toc = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jKkqYATmJ2Yk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "367df9cd-a9ab-4901-abca-aabde86cb8ec"
      },
      "cell_type": "code",
      "source": [
        "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vectorized loss: 2.345877e+00 computed in 0.015260s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GKMrMRPeKMLQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6fca02b5-30a7-4b80-c76c-9cff64516231"
      },
      "cell_type": "code",
      "source": [
        "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
        "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
        "print('Gradient difference: %f' % grad_difference)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss difference: 0.000000\n",
            "Gradient difference: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lamGwUOlOcsX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "class LinearClassifier(object):\n",
        "\n",
        "  def __init__(self):\n",
        "    self.W = None\n",
        "\n",
        "  def train(self, X, y, learning_rate=1e-3, reg=1e-5, num_iters=100,\n",
        "            batch_size=200, verbose=False):\n",
        "    \"\"\"\n",
        "    Train this linear classifier using stochastic gradient descent.\n",
        "\n",
        "    Inputs:\n",
        "    - X: A numpy array of shape (N, D) containing training data; there are N\n",
        "      training samples each of dimension D.\n",
        "    - y: A numpy array of shape (N,) containing training labels; y[i] = c\n",
        "      means that X[i] has label 0 <= c < C for C classes.\n",
        "    - learning_rate: (float) learning rate for optimization.\n",
        "    - reg: (float) regularization strength.\n",
        "    - num_iters: (integer) number of steps to take when optimizing\n",
        "    - batch_size: (integer) number of training examples to use at each step.\n",
        "    - verbose: (boolean) If true, print progress during optimization.\n",
        "\n",
        "    Outputs:\n",
        "    A list containing the value of the loss function at each training iteration.\n",
        "    \"\"\"\n",
        "    num_train, dim = X.shape\n",
        "    num_classes = np.max(y) + 1 # assume y takes values 0...K-1 where K is number of classes\n",
        "    if self.W is None:\n",
        "      # lazily initialize W\n",
        "      self.W = 0.001 * np.random.randn(dim, num_classes)\n",
        "\n",
        "    # Run stochastic gradient descent to optimize W\n",
        "    loss_history = []\n",
        "    for it in range(num_iters):\n",
        "      X_batch = None\n",
        "      y_batch = None\n",
        "\n",
        "      #########################################################################\n",
        "      # TODO:                                                                 #\n",
        "      # Sample batch_size elements from the training data and their           #\n",
        "      # corresponding labels to use in this round of gradient descent.        #\n",
        "      # Store the data in X_batch and their corresponding labels in           #\n",
        "      # y_batch; after sampling X_batch should have shape (dim, batch_size)   #\n",
        "      # and y_batch should have shape (batch_size,)                           #\n",
        "      #                                                                       #\n",
        "      # Hint: Use np.random.choice to generate indices. Sampling with         #\n",
        "      # replacement is faster than sampling without replacement.              #\n",
        "      #########################################################################\n",
        "      sample_choices = np.random.choice(np.arange(num_train),batch_size)\n",
        "      X_batch = X[sample_choices]\n",
        "      y_batch = y[sample_choices]\n",
        "      #########################################################################\n",
        "      #                       END OF YOUR CODE                                #\n",
        "      #########################################################################\n",
        "\n",
        "      # evaluate loss and gradient\n",
        "      loss, grad = self.loss(X_batch, y_batch, reg)\n",
        "      loss_history.append(loss)\n",
        "\n",
        "      # perform parameter update\n",
        "      #########################################################################\n",
        "      # TODO:                                                                 #\n",
        "      # Update the weights using the gradient and the learning rate.          #\n",
        "      #########################################################################\n",
        "      self.W = self.W - (learning_rate)*(grad)\n",
        "      #########################################################################\n",
        "      #                       END OF YOUR CODE                                #\n",
        "      #########################################################################\n",
        "\n",
        "      if verbose and it % 100 == 0:\n",
        "        print('iteration %d / %d: loss %f' % (it, num_iters, loss))\n",
        "\n",
        "    return loss_history\n",
        "\n",
        "  def predict(self, X):\n",
        "    \"\"\"\n",
        "    Use the trained weights of this linear classifier to predict labels for\n",
        "    data points.\n",
        "\n",
        "    Inputs:\n",
        "    - X: A numpy array of shape (N, D) containing training data; there are N\n",
        "      training samples each of dimension D.\n",
        "\n",
        "    Returns:\n",
        "    - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional\n",
        "      array of length N, and each element is an integer giving the predicted\n",
        "      class.\n",
        "    \"\"\"\n",
        "    y_pred = np.zeros(X.shape[0])\n",
        "    ###########################################################################\n",
        "    # TODO:                                                                   #\n",
        "    # Implement this method. Store the predicted labels in y_pred.            #\n",
        "    ###########################################################################\n",
        "    y_scores = np.dot(X,self.W)\n",
        "    y_pred = np.argmax(y_scores,axis=1)\n",
        "    ###########################################################################\n",
        "    #                           END OF YOUR CODE                              #\n",
        "    ###########################################################################\n",
        "    return y_pred\n",
        "  \n",
        "  def loss(self, X_batch, y_batch, reg):\n",
        "    \"\"\"\n",
        "    Compute the loss function and its derivative. \n",
        "    Subclasses will override this.\n",
        "\n",
        "    Inputs:\n",
        "    - X_batch: A numpy array of shape (N, D) containing a minibatch of N\n",
        "      data points; each point has dimension D.\n",
        "    - y_batch: A numpy array of shape (N,) containing labels for the minibatch.\n",
        "    - reg: (float) regularization strength.\n",
        "\n",
        "    Returns: A tuple containing:\n",
        "    - loss as a single float\n",
        "    - gradient with respect to self.W; an array of the same shape as W\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "class LinearSVM(LinearClassifier):\n",
        "  \"\"\" A subclass that uses the Multiclass SVM loss function \"\"\"\n",
        "\n",
        "  def loss(self, X_batch, y_batch, reg):\n",
        "    return svm_loss_vectorized(self.W, X_batch, y_batch, reg)\n",
        "\n",
        "\n",
        "class Softmax(LinearClassifier):\n",
        "  \"\"\" A subclass that uses the Softmax + Cross-entropy loss function \"\"\"\n",
        "\n",
        "  def loss(self, X_batch, y_batch, reg):\n",
        "    return softmax_loss_vectorized(self.W, X_batch, y_batch, reg)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mDOMXm-UKR9D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1445
        },
        "outputId": "f549fafa-a448-485c-de45-82f7282b1cd9"
      },
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "best_val = -1\n",
        "best_softmax = None\n",
        "learning_rates = [1e-7, 5e-7]\n",
        "regularization_strengths = [2.5e4, 5e4]\n",
        "\n",
        "################################################################################\n",
        "# TODO:                                                                        #\n",
        "# Use the validation set to set the learning rate and regularization strength. #\n",
        "# This should be identical to the validation that you did for the SVM; save    #\n",
        "# the best trained softmax classifer in best_softmax.                          #\n",
        "################################################################################\n",
        "for lr in learning_rates:\n",
        "  for reg in regularization_strengths:\n",
        "    smax=Softmax()\n",
        "    smax.train(X_train, y_train, learning_rate=lr, reg=reg, num_iters=2000,\n",
        "            batch_size=200, verbose=True)\n",
        "    y_pred_train = smax.predict(X_train)\n",
        "    train_accuracy = np.mean((y_pred_train==y_train))\n",
        "    y_pred_val  = smax.predict(X_val)\n",
        "    val_accuracy = np.mean((y_pred_val == y_val))\n",
        "    results[(lr,reg)] = (train_accuracy,val_accuracy)\n",
        "    if val_accuracy>best_val:\n",
        "      best_val = val_accuracy\n",
        "      best_softmax =smax \n",
        "    \n",
        "################################################################################\n",
        "#                              END OF YOUR CODE                                #\n",
        "################################################################################\n",
        "    \n",
        "# Print out results.\n",
        "for lr, reg in sorted(results):\n",
        "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
        "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
        "                lr, reg, train_accuracy, val_accuracy))\n",
        "    \n",
        "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 0 / 2000: loss 386.355008\n",
            "iteration 100 / 2000: loss 233.701239\n",
            "iteration 200 / 2000: loss 141.945944\n",
            "iteration 300 / 2000: loss 86.586726\n",
            "iteration 400 / 2000: loss 53.266325\n",
            "iteration 500 / 2000: loss 32.942346\n",
            "iteration 600 / 2000: loss 20.719947\n",
            "iteration 700 / 2000: loss 13.294985\n",
            "iteration 800 / 2000: loss 8.815135\n",
            "iteration 900 / 2000: loss 6.191437\n",
            "iteration 1000 / 2000: loss 4.542878\n",
            "iteration 1100 / 2000: loss 3.563741\n",
            "iteration 1200 / 2000: loss 2.867881\n",
            "iteration 1300 / 2000: loss 2.625798\n",
            "iteration 1400 / 2000: loss 2.351651\n",
            "iteration 1500 / 2000: loss 2.218230\n",
            "iteration 1600 / 2000: loss 2.149678\n",
            "iteration 1700 / 2000: loss 2.165224\n",
            "iteration 1800 / 2000: loss 1.990332\n",
            "iteration 1900 / 2000: loss 2.006824\n",
            "iteration 0 / 2000: loss 774.789926\n",
            "iteration 100 / 2000: loss 284.739668\n",
            "iteration 200 / 2000: loss 105.458606\n",
            "iteration 300 / 2000: loss 39.979561\n",
            "iteration 400 / 2000: loss 15.888963\n",
            "iteration 500 / 2000: loss 7.194416\n",
            "iteration 600 / 2000: loss 4.013617\n",
            "iteration 700 / 2000: loss 2.792188\n",
            "iteration 800 / 2000: loss 2.399708\n",
            "iteration 900 / 2000: loss 2.120505\n",
            "iteration 1000 / 2000: loss 2.115335\n",
            "iteration 1100 / 2000: loss 2.170430\n",
            "iteration 1200 / 2000: loss 2.070285\n",
            "iteration 1300 / 2000: loss 2.165113\n",
            "iteration 1400 / 2000: loss 2.081372\n",
            "iteration 1500 / 2000: loss 2.141422\n",
            "iteration 1600 / 2000: loss 2.011350\n",
            "iteration 1700 / 2000: loss 2.130302\n",
            "iteration 1800 / 2000: loss 2.131592\n",
            "iteration 1900 / 2000: loss 2.166016\n",
            "iteration 0 / 2000: loss 390.843378\n",
            "iteration 100 / 2000: loss 32.845461\n",
            "iteration 200 / 2000: loss 4.446689\n",
            "iteration 300 / 2000: loss 2.302615\n",
            "iteration 400 / 2000: loss 2.031705\n",
            "iteration 500 / 2000: loss 1.991082\n",
            "iteration 600 / 2000: loss 2.058048\n",
            "iteration 700 / 2000: loss 1.997178\n",
            "iteration 800 / 2000: loss 2.039668\n",
            "iteration 900 / 2000: loss 1.899360\n",
            "iteration 1000 / 2000: loss 2.017472\n",
            "iteration 1100 / 2000: loss 1.969007\n",
            "iteration 1200 / 2000: loss 2.037935\n",
            "iteration 1300 / 2000: loss 1.989798\n",
            "iteration 1400 / 2000: loss 1.980994\n",
            "iteration 1500 / 2000: loss 2.052060\n",
            "iteration 1600 / 2000: loss 2.028787\n",
            "iteration 1700 / 2000: loss 1.994339\n",
            "iteration 1800 / 2000: loss 2.072941\n",
            "iteration 1900 / 2000: loss 2.017345\n",
            "iteration 0 / 2000: loss 769.472593\n",
            "iteration 100 / 2000: loss 6.858130\n",
            "iteration 200 / 2000: loss 2.143092\n",
            "iteration 300 / 2000: loss 2.129537\n",
            "iteration 400 / 2000: loss 2.132793\n",
            "iteration 500 / 2000: loss 2.160687\n",
            "iteration 600 / 2000: loss 2.125363\n",
            "iteration 700 / 2000: loss 2.035867\n",
            "iteration 800 / 2000: loss 2.055091\n",
            "iteration 900 / 2000: loss 2.138058\n",
            "iteration 1000 / 2000: loss 2.065562\n",
            "iteration 1100 / 2000: loss 2.059030\n",
            "iteration 1200 / 2000: loss 2.055061\n",
            "iteration 1300 / 2000: loss 2.086325\n",
            "iteration 1400 / 2000: loss 2.074354\n",
            "iteration 1500 / 2000: loss 2.045338\n",
            "iteration 1600 / 2000: loss 2.116175\n",
            "iteration 1700 / 2000: loss 2.089675\n",
            "iteration 1800 / 2000: loss 2.042489\n",
            "iteration 1900 / 2000: loss 2.161396\n",
            "lr 1.000000e-07 reg 2.500000e+04 train accuracy: 0.351388 val accuracy: 0.367000\n",
            "lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.330265 val accuracy: 0.346000\n",
            "lr 5.000000e-07 reg 2.500000e+04 train accuracy: 0.354408 val accuracy: 0.363000\n",
            "lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.330898 val accuracy: 0.335000\n",
            "best validation accuracy achieved during cross-validation: 0.367000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eBy88J4qSipZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c12c28d0-f9b8-48c2-e8f0-67f67a27b965"
      },
      "cell_type": "code",
      "source": [
        "y_test_pred = best_softmax.predict(X_test)\n",
        "test_accuracy = np.mean(y_test == y_test_pred)\n",
        "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "softmax on raw pixels final test set accuracy: 0.364000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6SGdKkd9VUPt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "8880e2af-6d5e-435b-f9aa-f48763ece1b5"
      },
      "cell_type": "code",
      "source": [
        "w = best_softmax.W[:-1,:] # strip out the bias\n",
        "w = w.reshape(32, 32, 3, 10)\n",
        "\n",
        "w_min, w_max = np.min(w), np.max(w)\n",
        "\n",
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    \n",
        "    # Rescale the weights to be between 0 and 255\n",
        "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
        "    plt.imshow(wimg.astype('uint8'))\n",
        "    plt.axis('off')\n",
        "    plt.title(classes[i])"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAF7CAYAAAAkBgR2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f19163697b8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "x_1Jvh6YVdV1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}